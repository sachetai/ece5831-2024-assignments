{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1: Import Necessary Libraries -**"
      ],
      "metadata": {
        "id": "uSk1au0NQKPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVhYTqT0ci_e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from train import TwoLayerNetWithBackProp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 2: Load and Prepare the Data -**"
      ],
      "metadata": {
        "id": "_9G9tzOIQQ05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X = mnist.data / 255.0  # Normalize the data to [0, 1] range\n",
        "y = mnist.target.astype(int)  # Convert labels to integer type\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "ffIkaJuscl7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 3: Define Training Parameters -**"
      ],
      "metadata": {
        "id": "8FmfQiJwQVTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "iterations = 10000\n",
        "batch_size = 16\n",
        "learning_rate = 0.01\n",
        "train_size = X_train.shape[0]\n",
        "\n",
        "# Calculate iterations per epoch\n",
        "iter_per_epoch = train_size // batch_size"
      ],
      "metadata": {
        "id": "pgqxK3QRcl93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 4: Initialize and Train the Model -**"
      ],
      "metadata": {
        "id": "kelDM7oFQbY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TwoLayerNetWithBackProp model\n",
        "network = TwoLayerNetWithBackProp(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "# Lists to store training and test accuracy\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# Training loop\n",
        "for i in range(iterations):\n",
        "    # Generate a mini-batch\n",
        "    batch_indices = np.random.choice(train_size, batch_size)\n",
        "    X_batch = X_train[batch_indices]\n",
        "    y_batch = y_train[batch_indices]\n",
        "\n",
        "    # Calculate gradients using backpropagation and update parameters\n",
        "    grads = network.backward(X_batch, y_batch)\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grads[key]\n",
        "\n",
        "    # Record accuracy every epoch\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = accuracy_score(y_train, np.argmax(network.predict(X_train), axis=1))\n",
        "        test_acc = accuracy_score(y_test, np.argmax(network.predict(X_test), axis=1))\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(f\"Epoch {i // iter_per_epoch}: Train Accuracy = {train_acc:.4f}, Test Accuracy = {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "sDlDI2CkcmAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 5: Plot the Accuracy Graph -**"
      ],
      "metadata": {
        "id": "Sr27Pe5EQgt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy over epochs\n",
        "plt.plot(train_acc_list, label='Train Accuracy')\n",
        "plt.plot(test_acc_list, label='Test Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Test Accuracy Over Epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YPEwd2fudo6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to a file\n",
        "with open(\"utekar_mnist_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(network, f)"
      ],
      "metadata": {
        "id": "ZL0Ivl0Ddo84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Test Handwritten Digits Using module6.py -**"
      ],
      "metadata": {
        "id": "B3twHfJRQpfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# List of test images with their labels\n",
        "images = [\n",
        "    (\"./handwritten_digits/3_2.png\", 3),\n",
        "    (\"./handwritten_digits/5_1.png\", 5),\n",
        "    # Add more image paths and their correct labels here\n",
        "]\n",
        "\n",
        "# Run module6.py for each image\n",
        "for image_path, label in images:\n",
        "    result = subprocess.run([\"python\", \"module6.py\", image_path, str(label)], capture_output=True, text=True)\n",
        "    print(result.stdout)"
      ],
      "metadata": {
        "id": "Iqjh4hVbdsUj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}