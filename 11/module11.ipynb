{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **This notebook demonstrates the implementation of the classes: Imdb, Reuters, and BostonHousing.**\n",
        "\n",
        "##### Each class includes functions to prepare data, build a model, train, plot loss and accuracy, evaluate the model, and save it. All with appropriate docstrings and explanations."
      ],
      "metadata": {
        "id": "2fmkFq4zBwCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Import required libraries -**"
      ],
      "metadata": {
        "id": "XIJ6t55QBwLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb, reuters, boston_housing\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dyqMj5axB-tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. IMDB - Binary Classification -**"
      ],
      "metadata": {
        "id": "JMlcHZvGCMnd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myMECH06BpOH"
      },
      "outputs": [],
      "source": [
        "class Imdb:\n",
        "    \"\"\"\n",
        "    This class performs binary classification on the IMDB dataset (positive vs negative movie reviews).\n",
        "    It includes functions to prepare data, build a model, train, evaluate, and save the model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the IMDB classifier class with necessary attributes.\n",
        "        \"\"\"\n",
        "        self.x_train = None\n",
        "        self.x_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.vocab_size = 10000\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"\n",
        "        Prepares the IMDB dataset for training and testing.\n",
        "        - Loads data\n",
        "        - Tokenizes the text data\n",
        "        - Pads sequences to a fixed length\n",
        "        \"\"\"\n",
        "        (self.x_train, self.y_train), (self.x_test, self.y_test) = imdb.load_data(num_words=self.vocab_size)\n",
        "        self.x_train = tf.keras.preprocessing.sequence.pad_sequences(self.x_train, maxlen=500)\n",
        "        self.x_test = tf.keras.preprocessing.sequence.pad_sequences(self.x_test, maxlen=500)\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"\n",
        "        Builds the neural network model for binary classification.\n",
        "        - Embedding layer\n",
        "        - LSTM layer\n",
        "        - Dense layer with sigmoid activation\n",
        "        \"\"\"\n",
        "        self.model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Embedding(self.vocab_size, 128, input_length=500),\n",
        "            tf.keras.layers.LSTM(128),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def train(self, epochs=5, batch_size=64):\n",
        "        \"\"\"\n",
        "        Trains the model on the IMDB dataset.\n",
        "        \"\"\"\n",
        "        self.history = self.model.fit(self.x_train, self.y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"\n",
        "        Saves the trained model to a file.\n",
        "        \"\"\"\n",
        "        self.model.save('/Users/sachetutekar/PycharmProjects/ECE 5831/HW11/sachetutekar_IMDB.keras')\n",
        "\n",
        "    def plot_loss(self):\n",
        "        \"\"\"\n",
        "        Plots the loss during training.\n",
        "        \"\"\"\n",
        "        plt.plot(self.history.history['loss'], label='Training Loss')\n",
        "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"\n",
        "        Evaluates the model on the test set.\n",
        "        \"\"\"\n",
        "        loss, accuracy = self.model.evaluate(self.x_test, self.y_test)\n",
        "        print(f\"Test Loss: {loss}\")\n",
        "        print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 1: Initialize the IMDB object\n",
        "    imdb = Imdb()\n",
        "\n",
        "    # Step 2: Prepare the data\n",
        "    imdb.prepare_data()\n",
        "    print(\"Data preparation completed.\")\n",
        "\n",
        "    # Step 3: Build the model\n",
        "    imdb.build_model()\n",
        "    print(\"Model built successfully.\")\n",
        "\n",
        "    # Step 4: Train the model\n",
        "    print(\"Training started...\")\n",
        "    imdb.train(epochs=5, batch_size=32)\n",
        "    print(\"Training completed.\")\n",
        "\n",
        "    # Step 5: Plot loss and accuracy\n",
        "    print(\"Plotting training loss...\")\n",
        "    imdb.plot_loss()\n",
        "\n",
        "    print(\"Plotting training accuracy...\")\n",
        "    imdb.plot_accuracy()\n",
        "\n",
        "    # Step 6: Evaluate the model\n",
        "    print(\"Evaluating the model on test data...\")\n",
        "    imdb.evaluate()\n",
        "\n",
        "    imdb.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Reuters - Multiclass Classification -**"
      ],
      "metadata": {
        "id": "QLsfcY62CbMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Reuters:\n",
        "    \"\"\"\n",
        "    This class performs multiclass classification on the Reuters dataset (categorizing news articles).\n",
        "    It includes functions to prepare data, build a model, train, evaluate, and save the model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the Reuters classifier class with necessary attributes.\n",
        "        \"\"\"\n",
        "        self.x_train = None\n",
        "        self.x_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.num_classes = 46\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"\n",
        "        Prepares the Reuters dataset for training and testing.\n",
        "        - Loads data\n",
        "        - Tokenizes the text data\n",
        "        - Pads sequences to a fixed length\n",
        "        \"\"\"\n",
        "        (self.x_train, self.y_train), (self.x_test, self.y_test) = reuters.load_data(num_words=10000)\n",
        "        self.x_train = tf.keras.preprocessing.sequence.pad_sequences(self.x_train, maxlen=500)\n",
        "        self.x_test = tf.keras.preprocessing.sequence.pad_sequences(self.x_test, maxlen=500)\n",
        "        self.y_train = tf.keras.utils.to_categorical(self.y_train, num_classes=self.num_classes)\n",
        "        self.y_test = tf.keras.utils.to_categorical(self.y_test, num_classes=self.num_classes)\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"\n",
        "        Builds the neural network model for multiclass classification.\n",
        "        - Embedding layer\n",
        "        - LSTM layer\n",
        "        - Dense output layer with softmax activation\n",
        "        \"\"\"\n",
        "        self.model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Embedding(10000, 128, input_length=500),\n",
        "            tf.keras.layers.LSTM(128),\n",
        "            tf.keras.layers.Dense(self.num_classes, activation='softmax')\n",
        "        ])\n",
        "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def train(self, epochs=5, batch_size=64):\n",
        "        \"\"\"\n",
        "        Trains the model on the Reuters dataset.\n",
        "        \"\"\"\n",
        "        self.history = self.model.fit(self.x_train, self.y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"\n",
        "        Saves the trained model to a file.\n",
        "        \"\"\"\n",
        "        self.model.save('/Users/sachetutekar/PycharmProjects/ECE 5831/HW11/sachetutekar_REUTERS.keras')\n",
        "\n",
        "    def plot_loss(self):\n",
        "        \"\"\"\n",
        "        Plots the loss during training.\n",
        "        \"\"\"\n",
        "        plt.plot(self.history.history['loss'], label='Training Loss')\n",
        "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"\n",
        "        Evaluates the model on the test set.\n",
        "        \"\"\"\n",
        "        loss, accuracy = self.model.evaluate(self.x_test, self.y_test)\n",
        "        print(f\"Test Loss: {loss}\")\n",
        "        print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    reuters_classifier = Reuters()\n",
        "    reuters_classifier.prepare_data()\n",
        "    reuters_classifier.build_model()\n",
        "    reuters_classifier.train(epochs=5)\n",
        "    reuters_classifier.plot_loss()\n",
        "    reuters_classifier.plot_accuracy()\n",
        "    reuters_classifier.evaluate()\n",
        "    reuters_classifier.save_model()"
      ],
      "metadata": {
        "id": "cjw1tmmQCbYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. Boston Housing - Regression -**"
      ],
      "metadata": {
        "id": "3_xsOAQVCr4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BostonHousing:\n",
        "    \"\"\"\n",
        "    This class performs regression on the Boston Housing dataset (predicting house prices).\n",
        "    It includes functions to prepare data, build a model, train, evaluate, and save the model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the Boston Housing regression model class with necessary attributes.\n",
        "        \"\"\"\n",
        "        self.x_train = None\n",
        "        self.x_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"\n",
        "        Prepares the Boston Housing dataset for training and testing.\n",
        "        - Loads data\n",
        "        - Normalizes the data (feature scaling)\n",
        "        \"\"\"\n",
        "        (self.x_train, self.y_train), (self.x_test, self.y_test) = boston_housing.load_data()\n",
        "        mean = self.x_train.mean(axis=0)\n",
        "        std = self.x_train.std(axis=0)\n",
        "        self.x_train = (self.x_train - mean) / std\n",
        "        self.x_test = (self.x_test - mean) / std\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"\n",
        "        Builds the neural network model for regression.\n",
        "        - Dense layers with ReLU activation\n",
        "        - Single output layer for predicting house prices\n",
        "        \"\"\"\n",
        "        self.model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(64, activation='relu', input_shape=(self.x_train.shape[1],)),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1)  # Single output for regression\n",
        "        ])\n",
        "        self.model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "    def train(self, epochs=250, batch_size=32):\n",
        "        \"\"\"\n",
        "        Trains the model on the Boston Housing dataset.\n",
        "        \"\"\"\n",
        "        self.history = self.model.fit(self.x_train, self.y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"\n",
        "        Saves the trained model to a file.\n",
        "        \"\"\"\n",
        "        self.model.save('/Users/sachetutekar/PycharmProjects/ECE 5831/HW11/sachetutekar_BOSTON_HOUSING.keras')\n",
        "\n",
        "    def plot_loss(self):\n",
        "        \"\"\"\n",
        "        Plots the loss during training.\n",
        "        \"\"\"\n",
        "        plt.plot(self.history.history['loss'], label='Training Loss')\n",
        "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"\n",
        "        Evaluates the model on the test set.\n",
        "        \"\"\"\n",
        "        loss, mae = self.model.evaluate(self.x_test, self.y_test)\n",
        "        print(f\"Test Loss: {loss}\")\n",
        "        print(f\"Test MAE: {mae}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    boston_housing_model = BostonHousing()  # Rename variable to avoid conflict\n",
        "    boston_housing_model.prepare_data()\n",
        "    boston_housing_model.build_model()\n",
        "    boston_housing_model.train(epochs=50)\n",
        "    boston_housing_model.plot_loss()\n",
        "    boston_housing_model.evaluate()\n",
        "    boston_housing_model.save_model()"
      ],
      "metadata": {
        "id": "HSLUtwOMCsA0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}